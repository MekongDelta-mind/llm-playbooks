{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT5dxk8RfA53"
      },
      "source": [
        "# Chapter 2 Exercise 5\n",
        "\n",
        "Try out sentences and paragraphs in different styles and topics to see how the perplexity varies! In particular get the perplexities of these types of text:\n",
        "\n",
        "- Social media text, like Twitter\n",
        "- SEO spam\n",
        "- Text with a lot of slang\n",
        "\n",
        "Which documents have the highest perplexity? Which documents have the lowest perplexity? After manually inspecting the results, do you think perplexity sampling is a good measure of quality?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaMowwrifA55",
        "outputId": "eb174aa8-23a8-4737-83f4-a635e5375ed6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
            "  Downloading https://github.com/kpu/kenlm/archive/master.zip (553 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m553.6/553.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: kenlm\n",
            "  Building wheel for kenlm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kenlm: filename=kenlm-0.2.0-cp311-cp311-linux_x86_64.whl size=3186708 sha256=fa8c003b0f917c3d8ddeb91c7c32c5cc1443187b824b5dc0733806307f67402f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-h6cyryzx/wheels/4e/ca/6a/e5da175b1396483f6f410cdb4cfe8bc8fa5e12088e91d60413\n",
            "Successfully built kenlm\n",
            "Installing collected packages: kenlm\n",
            "Successfully installed kenlm-0.2.0\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Collecting huggingface\n",
            "  Downloading huggingface-0.0.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Downloading huggingface-0.0.1-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: huggingface\n",
            "Successfully installed huggingface-0.0.1\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.29.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.4.1-py3-none-any.whl (487 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.4.1 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install https://github.com/kpu/kenlm/archive/master.zip\n",
        "!pip install sentencepiece\n",
        "!pip install huggingface\n",
        "!pip install huggingface_hub\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import kenlm\n",
        "from huggingface_hub import hf_hub_download\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "YguNapIil02Q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "8fe7093f51574d6fa9b2f299ed631374",
            "b92d886ebabd4fe69ad9bd33196db451",
            "fdc9fe69df964cb99494062bef376cd9",
            "46944f284d124ef29589456734ae1f58",
            "94e061dc0ba247e996a7e3fa49380774",
            "e97caec680344a53a7bb76de22acf951",
            "a96887ccf0724563848ca11a332d1a08",
            "111167365d774d69a84b6ea101a7ba1f",
            "eb6f5dd2ef604206be3c9ee712791e61",
            "cb962b5ff5564e7ba4c524a27547fff9",
            "7e60fc89eaf14faca4afd66df798598d"
          ]
        },
        "id": "sSJaKJ-_fA56",
        "outputId": "94edb897-e48d-4495-f881-34248fdaa126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "en.arpa.bin:   0%|          | 0.00/4.44G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fe7093f51574d6fa9b2f299ed631374"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# load wikipedia english model\n",
        "class KenlmModel:\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, model_name: str):\n",
        "        # Download the model file from Hugging Face\n",
        "        model_path = hf_hub_download(repo_id=model_name, filename=\"wikipedia/en.arpa.bin\")\n",
        "        return kenlm.Model(model_path)\n",
        "\n",
        "# Usage, as the huggingface link is somewhat deprecated, and the documentation is not working\n",
        "model = KenlmModel.from_pretrained(\"edugp/kenlm\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "CmdBzxVEmmyk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "496a0a17-0c12-474d-b8ab-a2db8c30e9e3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Model from b'en.arpa.bin'>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTj8yiXHfA55",
        "outputId": "91425a5a-f98d-437f-fc74-fec4786c3914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity Score: 329968.53211806616\n"
          ]
        }
      ],
      "source": [
        "# Calculate perplexity for the given sentence\n",
        "sentence = \"She was a shriveling bumblebee, and he was a bumbling banshee, but they accepted a position at Gringotts because of their love for maple syrup.\"\n",
        "perplexity_score = model.perplexity(sentence)\n",
        "\n",
        "print(f\"Perplexity Score: {perplexity_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding Perplexity\n",
        "\n",
        "Perplexity is a measure of how well a probability model predicts a sample. In the context of language models (like the one used here, KenLM), it essentially tells us how surprised the model is when it sees a given sentence.\n",
        "\n",
        "- Lower Perplexity: Indicates that the model is less surprised by the sentence, meaning it finds the sentence more probable or more \"expected\" based on the data it was trained on.\n",
        "- Higher Perplexity: Indicates that the model is more surprised by the sentence, meaning it finds the sentence less probable or less \"unexpected\" based on its training data."
      ],
      "metadata": {
        "id": "MOwRGMb-mHh_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2TRWKjmfA56",
        "outputId": "a9047800-7c33-4ab2-ee4d-02283abb347b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Social Media Text: 584134.9458673951\n",
            "SEO Spam: 2797439.730260099\n",
            "Slang Text: 945663.204067629\n"
          ]
        }
      ],
      "source": [
        "# Get perplexity\n",
        "print(\"Social Media Text:\", model.perplexity(\"omg lol fr tho this is so cray cray 😭 #relatable\"))\n",
        "\n",
        "print(\"SEO Spam:\", model.perplexity(\"Buy cheap shoes online now! Best prices on designer footwear. Limited time offer, don't miss out!\"))\n",
        "\n",
        "print(\"Slang Text:\", model.perplexity(\"Yo, that dude was straight up bussin', no cap. Hella fire fit, ya feel?\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Social Media Text** (584134.9458673951): This extremely high perplexity score indicates that the language model finds social media text incredibly unpredictable. The model, trained on Wikipedia's formal content, struggles to process the abbreviations, slang, emojis, and informal sentence structures prevalent in social media. The vast difference between the training data and the social media example results in the model being highly \"surprised\" by each word, leading to this massive perplexity value.\n",
        "\n",
        "- **SEO Spam** (2797439.730260099): The astonishingly high perplexity for SEO spam suggests that this type of text is exceptionally distant from the model's learned patterns. While SEO spam might contain grammatically correct phrases, its repetitive nature, keyword stuffing, and focus on promotional language are vastly different from the encyclopedic style of Wikipedia. The model's inability to predict the highly specific vocabulary and structure of SEO spam results in an even greater level of \"surprise\" than with social media text.\n",
        "\n",
        "- **Slang Text** (945663.204067629): The substantial perplexity score for slang-heavy text confirms that the model finds it highly improbable. The use of non-standard vocabulary, informal grammar, and colloquial expressions creates a significant mismatch with the model's training data. The model's difficulty in predicting the next word within this context, due to its unfamiliarity with slang, leads to a high degree of \"surprise,\" resulting in this elevated perplexity score."
      ],
      "metadata": {
        "id": "KlPahoWNmvg6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perplexity Scores: What's Going On?\n",
        "\n",
        "- We got these numbers: 584134.94, 2797439.73, and 945663.20. These are \"perplexity\" scores.\n",
        "- Think of it like confusion: The higher the number, the more confused the computer model is.\n",
        "- Model learned from Wikipedia: It's used to formal, proper writing.\n",
        "- Social Media Text (584134.94):\n",
        "  - \"omg lol fr tho...\" completely throws it off.\n",
        "  - Abbreviations, slang, emojis – total mismatch.\n",
        "- SEO Spam (2797439.73):\n",
        "  - \"Buy cheap shoes online now!\" even worse.\n",
        "  - Repetitive sales talk = major confusion.\n",
        "- Slang Text (945663.20):\n",
        "  - \"Yo, that dude was...\" – another big number.\n",
        "  - Slang and informal language not understood.\n",
        "\n",
        "What it means:\n",
        "- Numbers show how well the model \"gets\" different writing styles.\n",
        "- Big numbers = far from what it learned.\n",
        "\n",
        "**Important**:\n",
        "- Perplexity isn't perfect.\n",
        "- Low number doesn't always mean \"good\" text.\n",
        "- It's a way to see how well the language model fits the text that is being analysed."
      ],
      "metadata": {
        "id": "FqMpUtcYoGF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kenlm\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "class KenlmModel:\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, model_name: str):\n",
        "        # Download the model file from Hugging Face\n",
        "        model_path = hf_hub_download(repo_id=model_name, filename=\"wikipedia/en.arpa.bin\")\n",
        "        return kenlm.Model(model_path)\n",
        "\n",
        "def calculate_perplexity(model, sentence):\n",
        "    \"\"\"Calculate perplexity of a sentence using a KenLM model\"\"\"\n",
        "    # Calculate perplexity\n",
        "    log_prob = model.score(sentence, bos=True, eos=True)\n",
        "    words = len(sentence.split())\n",
        "    perplexity = 10 ** (-log_prob / words)\n",
        "\n",
        "    return perplexity\n"
      ],
      "metadata": {
        "id": "F3p7Xi7Mt5Qp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Downloading KenLM Wikipedia English model...\")\n",
        "# Load the Wikipedia English model using the provided class\n",
        "model = KenlmModel.from_pretrained(\"edugp/kenlm\")\n",
        "print(\"Model downloaded and loaded successfully!\")\n",
        "\n",
        "# Target sentence\n",
        "sentence = \"She was a shriveling bumblebee, and he was a bumbling banshee, but they accepted a position at Gringotts because of their love for maple syrup.\"\n",
        "\n",
        "# Calculate perplexity\n",
        "perplexity = calculate_perplexity(model, sentence)\n",
        "\n",
        "# Print results\n",
        "print(\"\\nPerplexity Analysis:\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"Sentence: {sentence}\")\n",
        "print(f\"Perplexity Score: {perplexity:.4f}\")\n",
        "\n",
        "# For comparison, calculate perplexity for a more common sentence\n",
        "common_sentence = \"The president spoke to the press about the new economic policies.\"\n",
        "common_perplexity = calculate_perplexity(model, common_sentence)\n",
        "\n",
        "print(\"\\nComparison with common sentence:\")\n",
        "print(f\"Sentence: {common_sentence}\")\n",
        "print(f\"Perplexity Score: {common_perplexity:.4f}\")\n",
        "\n",
        "# Calculate the ratio\n",
        "ratio = perplexity / common_perplexity\n",
        "print(f\"\\nThe target sentence is {ratio:.2f}x more surprising to the model than the common sentence.\")\n",
        "\n",
        "# Additional examples for comparison\n",
        "print(\"\\nAdditional Comparisons:\")\n",
        "\n",
        "# A highly formal sentence\n",
        "formal = \"The distinguished representatives convened to deliberate upon matters of international significance.\"\n",
        "formal_perplexity = calculate_perplexity(model, formal)\n",
        "print(f\"Formal sentence: {formal}\")\n",
        "print(f\"Perplexity: {formal_perplexity:.4f}\")\n",
        "\n",
        "# A very simple sentence\n",
        "simple = \"The cat sat on the mat.\"\n",
        "simple_perplexity = calculate_perplexity(model, simple)\n",
        "print(f\"Simple sentence: {simple}\")\n",
        "print(f\"Perplexity: {simple_perplexity:.4f}\")\n",
        "\n",
        "# A sentence with fantasy elements similar to the target\n",
        "fantasy = \"The wizard cast a spell on the dragon while the elves danced in the moonlight.\"\n",
        "fantasy_perplexity = calculate_perplexity(model, fantasy)\n",
        "print(f\"Fantasy sentence: {fantasy}\")\n",
        "print(f\"Perplexity: {fantasy_perplexity:.4f}\")\n"
      ],
      "metadata": {
        "id": "0mAQVIg8oiUU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31a4fcf2-f6bf-4d99-88f4-29f280b4387b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading KenLM Wikipedia English model...\n",
            "Model downloaded and loaded successfully!\n",
            "\n",
            "Perplexity Analysis:\n",
            "------------------------------------------------------------\n",
            "Sentence: She was a shriveling bumblebee, and he was a bumbling banshee, but they accepted a position at Gringotts because of their love for maple syrup.\n",
            "Perplexity Score: 548543.9453\n",
            "\n",
            "Comparison with common sentence:\n",
            "Sentence: The president spoke to the press about the new economic policies.\n",
            "Perplexity Score: 595201.6117\n",
            "\n",
            "The target sentence is 0.92x more surprising to the model than the common sentence.\n",
            "\n",
            "Additional Comparisons:\n",
            "Formal sentence: The distinguished representatives convened to deliberate upon matters of international significance.\n",
            "Perplexity: 4161921.7104\n",
            "Simple sentence: The cat sat on the mat.\n",
            "Perplexity: 1458355.8227\n",
            "Fantasy sentence: The wizard cast a spell on the dragon while the elves danced in the moonlight.\n",
            "Perplexity: 338976.9645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "py852EJba-v_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llm-playbooks",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8fe7093f51574d6fa9b2f299ed631374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b92d886ebabd4fe69ad9bd33196db451",
              "IPY_MODEL_fdc9fe69df964cb99494062bef376cd9",
              "IPY_MODEL_46944f284d124ef29589456734ae1f58"
            ],
            "layout": "IPY_MODEL_94e061dc0ba247e996a7e3fa49380774"
          }
        },
        "b92d886ebabd4fe69ad9bd33196db451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e97caec680344a53a7bb76de22acf951",
            "placeholder": "​",
            "style": "IPY_MODEL_a96887ccf0724563848ca11a332d1a08",
            "value": "en.arpa.bin: 100%"
          }
        },
        "fdc9fe69df964cb99494062bef376cd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_111167365d774d69a84b6ea101a7ba1f",
            "max": 4444690658,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb6f5dd2ef604206be3c9ee712791e61",
            "value": 4444690658
          }
        },
        "46944f284d124ef29589456734ae1f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb962b5ff5564e7ba4c524a27547fff9",
            "placeholder": "​",
            "style": "IPY_MODEL_7e60fc89eaf14faca4afd66df798598d",
            "value": " 4.44G/4.44G [01:54&lt;00:00, 41.3MB/s]"
          }
        },
        "94e061dc0ba247e996a7e3fa49380774": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e97caec680344a53a7bb76de22acf951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a96887ccf0724563848ca11a332d1a08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "111167365d774d69a84b6ea101a7ba1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb6f5dd2ef604206be3c9ee712791e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb962b5ff5564e7ba4c524a27547fff9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e60fc89eaf14faca4afd66df798598d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}